## Hyperparameters 
Parameters that affect the performance and structure of an ML algorithm

## 1 Choose tunable hyperparameter, then 
## 2 choose a range of values SageMaker can use on that tunable hyperparameter. Then,
## 3 choose the objective metric we want SageMaker to watch as it adjusts the tunable hyperparameter.

**For Example**
* Decision trees: Depth, max number of splits, impurity measure (entropy, gini etc.)
* K Nearest Neighbors: K (number of neighbors)
* Ensemble Bagging model: Number of individual models

* Grid Search - Brute force/exhaustive tuning
Alternative is
* Random Search - randomly tuning the parameters

* Bayesian Search - Keeps track of last hypertuning evaluations and build probablistic model


