## Sagemaker Automatic Model Tuning
1. Hyperparameter: values set prior to training
2. Parameter: values obtained by the training process like weights.

### Steps
1. Select **Metric** :  recall/precision
2. Select **Algorithm** : XGBoost, Linear Learner
3. Select **Range** of Hyperparameter: eta, gamma, lambda

### Search
1. Random: just random brute force.
2. Bayesian: learn from past and choose next. Learn by applying exploration and exploitation

#### Best Practices for Automatic Model Tuning
1. Avoid optimizing many Metrics at once (capped at 20)
2. Use Logarithmic scale
3. Use small range
4. Avoid Parallel training as with Sequential, it learns from last

## Deep learning on AWS

1. EC2 - P3, G3
2. EMR - Apache MXNet and GPU instance types

## DeepLearning [frameworks](https://aws.amazon.com/machine-learning/amis/)
<img src="https://i.imgur.com/wxSIqHH.png" width="500" />

| Algorithm | Use |
|:----------|:----|
| BlazingText, Word2Vec | generation of word embeddings from a large number of documents.|
| Sequence2Sequence | A general-purpose __encoder-decoder__ for text that is often used for machine translation, __text summarization__, etc.|
| Latent Dirichlet Allocation (LDA)| automatically discovering the main topics present in a set of __text__ files.|
| Neural Topic Modelling (NTM)| A neural network based approach for learning topics from __text and image__ datasets.|
| Object2Vec | A neural-embedding algorithm to compute nearest neighbors and to visualize natural clusters.|
| Linear Learner (Classification)| Uses an objectâ€™s characteristics to group|
| Linear Learner (Regression) | Predict the linear relationship between two variables|
| Factorization Machines | Estimate all of the interactions between features even with a very small amount of data.|
| Gradient Boosted Trees (XGBoost)| optimized distributed gradient boosting library.|
| Image Classification (ResNet) | A popular neural network for developing image classification systems.|
| IP Insights | Detect malicious users or learn to usage patterns of IP addresses.|
| Object Detection | Detects, classifies, and places bounding boxes around multiple objects in an image.|
| Semantic Segmentation| Partitions an image to identify places of interest by assigning a label to the individual pixels of the image.|
| Principal Component Analysis (PCA) | Often used in data pre-processing, reduces features |
| Random Cut Forest | An unsupervised machine learning algorithm for anomaly detection.|
| K-Means Clustering | find groups within unlabeled data.|
| K-Nearest Neighbor (k-NN)| An index based algorithm to address classification and regression|
| DeepAR :|time-series forecasts using RNN|

# AWS Image Algorithms | Supervised

<img src="https://miro.medium.com/max/5856/1*Hz6t-tokG1niaUfmcysusw.jpeg" height="300" />

1. Image Classification | ResNet | CNN
2. Object Detection | ResNet | VGG (Visual Geometry Group)
3. Semantic segmentation | MXNet GlueOn CV | FCN Fully Convolutional Network

### Hyperparameter
- Optimizer : SGD, adam, rmsprop, adadelta

### Input Parameters
Input: RecordIO, png, jpg, x-image

Annotation file parameters:
- file
- image_size
- annotations: bounding box, image class (1,2)
- categories: mapping of class index (1,2) and name (car/person)

### Instance types
- Training GPU P3
- Inference CPU C5 (cheap) and GPU P3 (Performance)

**************************************************************

## Linear Learner | Supervised | Continues discrete data
Uses: Regression, Classification

### Hyperparameter
- L1 regularization
- Wd L2 regularization
- Momentum: SGD

### Process Flow
Preprocessing: 
- Normalized data
Training: 
- Used SGD Stochastic Gradient Decent, 
- use Regularization L2
- Regression - predictor_type:'regressor'
- Classification - predictor_type:'binary_classifier'
Validation: 
- Regression - RMSE, ROC, AUC
- Classification Confusion Matrix

### Input
Input: RecordIO, Text/CSV, File and Pipe

### Instance types
- Training CPU or GPU
- Inference CPU is cost-efficient

**************************************************************

## Factorization Machine | Supervised | Extension to LL for highly SPARSE data (ClickStream ad recommendation)
Amazon Personalize

### Hyperparameters
- bias_init_method: 
  - Normal, 
  - Uniform, 
  - Constant
- Predictor Type:
  - regressor
  - binary_classifier
- num_factors: dimensionality

### Input
- CSV doesn't work with sparse data
- recordIO-protobuf Float32

### Instance Type
- Training CPU as sparse data(GPU is mostly for dense)
- Inference 

**************************************************************

## XGBoost | Supervised | COMPLEX Distribution | Powerful Ensemble Algorithm - quite popular

- handles versatile data types and complex distributions
- many tunable hyperparameters

- Popular for Fraud detection

### Hyperparameter
Alpha: L1
Lambda: L2
Booster
Eta: Step Size
Gamma: Min loss reduction needed to add more partition to tree

### Input
- uses Tabular data CSV, libSVM
- doesn't support protobuf

### Instance
Only CPU C5,M5

**************************************************************

## Seq2Seq | Supervised | RNN and CNN
- Machine Translation: Translate
- Speech to Text: Transcribe
- Text Summarization: Mphasis DeepInsights Text Summarizer 

Layers in SEQ2SEQ
1. Embedding Layer: sparse ONE hot encoded
2. Encoder layer: LSTM or GRU
3. Decoder layer: RNN and LSTM

### Hyperparameters
- cnn_activation_type: CNN
- encoder_type: RNN/CNN
- Optimizer_type: SGD,adam, rmsprop
- num_layers_encoder: for RNN or CNN
- num_layers_decoder: for RNN or CNN

### Flow | Attention mechanism
Input Data
- RecordIO-Protobuf
- Tokens in integer form with floating point formatting norm.
Training:
- train.rec
- val.rec
- vocab.trg.json

### Instance size
Only GPU P3

**************************************************************

## DeepAR | RNN | Supervised | TimeSeries forecasting with seasonality

- Point Forecast (Number products sold next month) - Amazon Forecast
- probabilistic forecast (Percentage products sold next month)
- Generative Music: Amazon DeepComposer

Popular Application
- Product demand Planning: Product inventory 
- Financial Planning: sales revenue
- Resource Planning: advertising, employees

### Input
- json, gzip, parquet
Data specification:
- Start: starting timestamp
- Target: time series values
- Dynamic_feat: if promotion was applied for product

### Hyperparameters
- context_length: time-points model sees for making prediction
- prediction_length: time-point model has to predict
- dropout_rate
- num_dynamic_feat

### Instance Types
- Training: CPU or use GPU only if required
- Inference: CPU Only

**************************************************************

## Blazing Text | NLP| Word2Vec and Text Classification under the hood

Uses:
- Document Classification: Word2Vec, Macie (UnSupervised)
- Sentiment Analysis - Comprehend (Supervised)

CBOW vs SKIMGram
<img src="https://i.imgur.com/KddLhjR.png" width="300" />

### Required Input as
- Each line of the input file contains a training sentence per line, along with their labels. 
- Labels must be prefixed with \__label__, and the tokens within the sentence including punctuation should be __space__ separated.
<img src="https://i.imgur.com/ItjpHXi.png" width="500" />

### Word2Vec Hyperparameters:
-  Mode: SKIMgram, CBOW

### Text Classification Hyperparameters:
-  Mode: Supervised and unSupervised

### Instance
CPU or GPU if needed

**************************************************************

## RandomCut Forest | Anomaly Detection

Default: Score more than 3 standard deviation is an Anomaly

### Input
text, csv, x-recordio-protobuf

### Hyperparameters
- eval_metrics: precision, recall, f1-score
- num_trees - 100 trees recommended
- num_sample
  
**************************************************************

## K NN | Supervised Classification or Regression
- Intuition based pick closest points | __Euclidean Distance__

- __Classification__: Most closer point red dots(category x) than blue (category y)
- __Regression__: Average value of closet points
<img src="https://i.imgur.com/BlCd3cF.png" width="500" />

### Instance
CPU if required GPU

`Note K=1 can cause OVERfitting since it considers only one neighboring point`

**********************************************************************

## K-Means | Unsupervised Clustering

- Group values with similar attributes
- Use Euclidean distance (like KNN)
- find center of K-cluster
- __K-Means++__ allowed allow cluster to be set away from each other
  

### Hyperparameter
- K- number of clusters
- init_method: how to choose initial clusters
- eval_metrix
- extra_center_factor

### Instance
CPU, GPU if required

**********************************************************************
## PCA | Dimensionality Reduction

- perform covariance matrix first
- then single value decomposition

### Mode
1. Regular
2. Randomized - better for larger observation

**********************************************************************
## IP Insights | Unsupervised | Amazon Guard Duty | Fraud Detector

 - learning the usage patterns for various IPv4 addresses.
 - Learning relationship between various entities and IPv4 addresses.

**********************************************************************

## Re-enforcement Learning | DeepRacer MXNet and TensorFlow

__MDP Markov Decision Process__
- Environment: stimulation or real world
- State: start, stop
- Action: right turn
- Reward
- Observation: track it is running on

### Instance
GPU recommended

**********************************************************************
## LDA | Light Weight Cost effective | Unsupervised
- Topic modeling by sampling words

### Instance
CPU is fine

## NTM DeepLearning | Unsupervised
- DeepLearning based Topic Modeling (Better than LDA)
- based on latent representation of top ranking words
- Need Tokenized Input

### Instance
Training - GPU Recommended
Inference - CPU

### LDA and NTM accepts only csv file format and recordIO-wrapped-protobuf format

**********************************************************************
## Object2Vec | CNN | Label Encoding

- General-purpose customizable neural embedding algorithm which can be used to embed sentence, movies and products.

__Example__: You want to create embeddings for the facebook statuses to show the similarity between the statuses.

https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object2vec_sentence_similarity/object2vec_sentence_similarity.ipynb

