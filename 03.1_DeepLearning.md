# Deep Learning Algorithms

<img src="https://i.imgur.com/Xri0x7w.png" height="400" />

## 1. FeedForward Neural Networks | Sup | Classification
Bias: helps to not get deactivation of neuron having -ve x value up to certain threshold.
<img src="https://i.imgur.com/VB4n0DF.png" height="300" />

```
Equation: A x + B
A - input
x - weights
B - Bias
```

### Activation Functions
<img src="https://i.imgur.com/6IWEhKN.png" height="300" />

- Sigmoid: [0-1] | __Output layers__
- ReLu : [no negative value] does not saturate so used in __hidden layers__
        Avoid vanishing gradient problem
- Tanh : [-1,1] | __output layer__ | preferable over sigmoid

<img src="https://i.imgur.com/uyuRqV8.png" height="400" />

### Multilayer Perception Network MLP
Represented by __matrix__ of weights
<img src="https://i.imgur.com/sBJRDIi.png" height="300" />

## 2. Convolutional Neural Networks CNN | Sup | Classification
Example: Image classification, spatial analysis, hotdog or not

Process image layer by layer over edge detection filter or multiple other filters
<img src="https://i.imgur.com/X4YLwlG.png" height="300" />

## 3. Recurrent Neural Network | Sup | Other
Example: Stock Prediction, Time Serries, Voice recognition (Seq2Seq), 
PATTERN which says Start activity - following certain sequence - End activity

<img src="https://i.imgur.com/YIWwPYI.png" height="300" />

### LSTM | more memory than RNNs